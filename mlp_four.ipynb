{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e97d8e4c-b39d-4c47-8138-b95c6f2ed039",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# consts\n",
    "PREV_CHAR_COUNT = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01b2d62-f1f2-44ad-962e-dafce20e8297",
   "metadata": {},
   "source": [
    "## Character mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "217218c0-058a-40e8-b74f-7c5a35cf4620",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Denotes beginning and end\n",
    "SPECIAL_CHAR = '.'\n",
    "CHAR_TO_ID_STR = SPECIAL_CHAR + 'abcdefghijklmnopqrstuvwxyz'\n",
    "\n",
    "char_to_id = {}\n",
    "id_to_char = []\n",
    "\n",
    "for i in range(len(CHAR_TO_ID_STR)):\n",
    "    c = CHAR_TO_ID_STR[i]\n",
    "    id_to_char.append(c)\n",
    "    char_to_id[c] = i\n",
    "\n",
    "NUM_CHAR = len(id_to_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593475b4-daab-45f9-873e-2ddbd2643f5f",
   "metadata": {},
   "source": [
    "## Load the text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77286264-f3ef-47f1-aaba-008ed4b25792",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "words = open('data/names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92ee45db-ec40-42e4-8f30-e5a1e86983fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eeaa142-992c-42c0-9200-ad5faea13142",
   "metadata": {},
   "source": [
    "## Word to labeled pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1f22829-d553-4ef7-931d-bb1bca126270",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def word_to_labeled_pairs(word: str, prev_char_count: int, char_to_id):\n",
    "    \"\"\"\n",
    "    Given a word (E.g. \"emma\") and prev_char_count, e.g. 3, return [xs,ys], the labeled data for learning.\n",
    "    Conceptually, the returned xs, ys are like so:\n",
    "    ... -> e\n",
    "    ..e -> m\n",
    "    .em -> m\n",
    "    emm -> a\n",
    "    mma -> .\n",
    "    \n",
    "    Each xs is an int array of size 3.\n",
    "    Each ys is an int.\n",
    "    char_to_id is in charge of mapping\n",
    "    \"\"\"\n",
    "    xs = []\n",
    "    ys = []\n",
    "    expanded_word = [SPECIAL_CHAR] * prev_char_count + list(word) + [SPECIAL_CHAR]\n",
    "    for left in range(len(word) + 1):\n",
    "        xs.append([char_to_id[expanded_word[left + offset]] for offset in range(prev_char_count)])\n",
    "        ys.append(char_to_id[expanded_word[left + prev_char_count]])\n",
    "    return xs, ys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "28722f9f-4368-4eb7-9948-6e0972d9db67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.', '.', '.'] -> e\n",
      "['.', '.', 'e'] -> m\n",
      "['.', 'e', 'm'] -> m\n",
      "['e', 'm', 'm'] -> a\n",
      "['m', 'm', 'a'] -> .\n"
     ]
    }
   ],
   "source": [
    "xs, ys = word_to_labeled_pairs(\"emma\", PREV_CHAR_COUNT, char_to_id)\n",
    "for i in range(len(ys)):\n",
    "    print(f\"{[id_to_char[x] for x in xs[i]]} -> {id_to_char[ys[i]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ceaa1db-3a48-4dce-8d91-590145b488ea",
   "metadata": {},
   "source": [
    "## Mini training data - just first 5 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5f3b4fbe-c2e3-4e2b-95c7-f2426abbbf65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mini_x, mini_y = [], []\n",
    "for word in words[:5]:\n",
    "    xs, ys = word_to_labeled_pairs(word, PREV_CHAR_COUNT, char_to_id)\n",
    "    mini_x.extend(xs)\n",
    "    mini_y.extend(ys)\n",
    "mini_x = torch.tensor(mini_x)\n",
    "mini_y = torch.tensor(mini_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e87a3af4-207f-46e0-97ae-ef10db58cb4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3]), torch.int64, torch.Size([32]), torch.int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_x.shape, mini_x.dtype, mini_y.shape, mini_y.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3325a74-f674-4af7-b4e0-b0c92ab25da4",
   "metadata": {},
   "source": [
    "## Model\n",
    "- Input dim: (N,3) = (input size, num context word)\n",
    "- Embed w/ size 2: (N, 6)\n",
    "- FCC layer: tanh(W1x + b1): (N, 100)\n",
    "- Compute logit: W2x + b2: (N, 27)\n",
    "- Model is complete here!\n",
    "- But for loss, we add cross-entropy against the Y's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5c40f667-ab4c-4953-b63e-0ce87ac05b0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# consts\n",
    "N = len(mini_y)\n",
    "EMBED_SIZE = 2\n",
    "EMBED_CONCAT_VEC_SIZE = EMBED_SIZE * PREV_CHAR_COUNT\n",
    "NUM_HIDDEN_NEURON = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1a9ca5fe-0ab3-4cb8-99b2-14ba868e552b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# params\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "embed = torch.randn((NUM_CHAR, embed_size), generator = g)\n",
    "w1 = torch.randn((EMBED_CONCAT_VEC_SIZE, NUM_HIDDEN_NEURON), generator = g)\n",
    "b1 = torch.randn((NUM_HIDDEN_NEURON), generator = g)\n",
    "w2 = torch.randn((NUM_HIDDEN_NEURON, NUM_CHAR), generator = g)\n",
    "b2 = torch.randn((NUM_CHAR), generator = g)\n",
    "params = [embed, w1, b1, w2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "042ef86c-0de9-44de-8a8c-dfa18f990cb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model\n",
    "\n",
    "# [LAYER] Embedding. \n",
    "# embed (27,2), mini_x (32,3) -> (32,3,2) -- do embedding lookup\n",
    "x_looked_up = embed[mini_x]\n",
    "assert x_looked_up.shape == (N, PREV_CHAR_COUNT, EMBED_SIZE)\n",
    "x_looked_up_shaped = x_looked_up.view(N, EMBED_CONCAT_VEC_SIZE)\n",
    "assert x_looked_up_shaped.shape == (N, EMBED_CONCAT_VEC_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "278bcb8d-c2bc-43d7-8400-194655de2fb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [LAYER] FCC\n",
    "fcc = (x_looked_up_shaped @ w1 + b1).tanh()\n",
    "assert fcc.shape == (N, NUM_HIDDEN_NEURON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f1aadd29-f647-4f52-b976-59c75cdfe4c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [LAYER] logit\n",
    "logits = fcc @ w2 + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cd56c0b8-940d-449a-869b-f3fbf0c7bc62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [Loss layer]\n",
    "loss = F.cross_entropy(logits, mini_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "444f4b80-c693-4113-9c31-9bcb8d01c256",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12.4674)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac0bd5c-ad3b-46ce-9263-a0b839c7c54a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
