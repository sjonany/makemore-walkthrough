{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e97d8e4c-b39d-4c47-8138-b95c6f2ed039",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# consts\n",
    "PREV_CHAR_COUNT = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01b2d62-f1f2-44ad-962e-dafce20e8297",
   "metadata": {},
   "source": [
    "## Character mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "217218c0-058a-40e8-b74f-7c5a35cf4620",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Denotes beginning and end\n",
    "SPECIAL_CHAR = '.'\n",
    "CHAR_TO_ID_STR = SPECIAL_CHAR + 'abcdefghijklmnopqrstuvwxyz'\n",
    "\n",
    "char_to_id = {}\n",
    "id_to_char = []\n",
    "\n",
    "for i in range(len(CHAR_TO_ID_STR)):\n",
    "    c = CHAR_TO_ID_STR[i]\n",
    "    id_to_char.append(c)\n",
    "    char_to_id[c] = i\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593475b4-daab-45f9-873e-2ddbd2643f5f",
   "metadata": {},
   "source": [
    "## Load the text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77286264-f3ef-47f1-aaba-008ed4b25792",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "words = open('data/names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92ee45db-ec40-42e4-8f30-e5a1e86983fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eeaa142-992c-42c0-9200-ad5faea13142",
   "metadata": {},
   "source": [
    "## Word to labeled pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1f22829-d553-4ef7-931d-bb1bca126270",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def word_to_labeled_pairs(word: str, prev_char_count: int, char_to_id):\n",
    "    \"\"\"\n",
    "    Given a word (E.g. \"emma\") and prev_char_count, e.g. 3, return [xs,ys], the labeled data for learning.\n",
    "    Conceptually, the returned xs, ys are like so:\n",
    "    ... -> e\n",
    "    ..e -> m\n",
    "    .em -> m\n",
    "    emm -> a\n",
    "    mma -> .\n",
    "    \n",
    "    Each xs is an int array of size 3.\n",
    "    Each ys is an int.\n",
    "    char_to_id is in charge of mapping\n",
    "    \"\"\"\n",
    "    xs = []\n",
    "    ys = []\n",
    "    expanded_word = [SPECIAL_CHAR] * prev_char_count + list(word) + [SPECIAL_CHAR]\n",
    "    for left in range(len(word) + 1):\n",
    "        xs.append([char_to_id[expanded_word[left + offset]] for offset in range(prev_char_count)])\n",
    "        ys.append(char_to_id[expanded_word[left + prev_char_count]])\n",
    "    return xs, ys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "28722f9f-4368-4eb7-9948-6e0972d9db67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.', '.', '.'] -> e\n",
      "['.', '.', 'e'] -> m\n",
      "['.', 'e', 'm'] -> m\n",
      "['e', 'm', 'm'] -> a\n",
      "['m', 'm', 'a'] -> .\n"
     ]
    }
   ],
   "source": [
    "xs, ys = word_to_labeled_pairs(\"emma\", PREV_CHAR_COUNT, char_to_id)\n",
    "for i in range(len(ys)):\n",
    "    print(f\"{[id_to_char[x] for x in xs[i]]} -> {id_to_char[ys[i]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ceaa1db-3a48-4dce-8d91-590145b488ea",
   "metadata": {},
   "source": [
    "## Mini training data - just first 5 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5f3b4fbe-c2e3-4e2b-95c7-f2426abbbf65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mini_x, mini_y = [], []\n",
    "for word in words[:5]:\n",
    "    xs, ys = word_to_labeled_pairs(word, PREV_CHAR_COUNT, char_to_id)\n",
    "    mini_x.extend(xs)\n",
    "    mini_y.extend(ys)\n",
    "mini_x = torch.tensor(mini_x)\n",
    "mini_y = torch.tensor(mini_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e87a3af4-207f-46e0-97ae-ef10db58cb4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3]), torch.int64, torch.Size([32]), torch.int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_x.shape, mini_x.dtype, mini_y.shape, mini_y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66a53aa-52bd-42d5-b853-5361c9b04d60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
